{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "403e2fe0-29b0-4ec1-b481-ba6ecfaf86c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the permalink of the company to search:  konsus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call successful!\n",
      "Data has been saved to company_data.parquet\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data_from_api(url, headers, params):\n",
    "    \"\"\"\n",
    "    Fetch data from the Crunchbase API.\n",
    "\n",
    "    Args:\n",
    "    - url (str): The API endpoint URL.\n",
    "    - headers (dict): The headers to be sent with the request.\n",
    "    - params (dict): The query parameters for the API request.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Parsed JSON response from the API.\n",
    "    - None: If there's an error in fetching the data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            # Success, return the data\n",
    "            print(\"API call successful!\")\n",
    "            data = response.json()\n",
    "            return(data)\n",
    "        else:\n",
    "            # Error handling\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_fields(data):\n",
    "    \"\"\"\n",
    "    Extract specific fields from the JSON data.\n",
    "\n",
    "    Args:\n",
    "    - data (dict): The JSON data.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with the extracted fields.\n",
    "    - None: If the extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract the necessary fields from 'cards' > 'fields'\n",
    "        fields = data.get('cards', {}).get('fields', {})\n",
    "        \n",
    "        permalink = fields.get('identifier', {}).get('permalink')\n",
    "        website_url = fields.get('website_url')\n",
    "        updated_at = fields.get('updated_at')\n",
    "        linkedin_value = fields.get('linkedin', {}).get('value')\n",
    "\n",
    "        # Extract city, region, and country from location_identifiers nested object\n",
    "        location_identifiers = fields.get('location_identifiers', [])\n",
    "\n",
    "        city = next((item['value'] for item in location_identifiers if item['location_type'] == 'city'), None)\n",
    "        region = next((item['value'] for item in location_identifiers if item['location_type'] == 'region'), None)\n",
    "        country = next((item['value'] for item in location_identifiers if item['location_type'] == 'country'), None)\n",
    "\n",
    "        extracted_data = {\n",
    "            \"permalink\": permalink,\n",
    "            \"website_url\": website_url,\n",
    "            \"updated_at\": updated_at,\n",
    "            \"linkedin\": linkedin_value,\n",
    "            \"city\": city,\n",
    "            \"region\": region,\n",
    "            \"country\": country\n",
    "        }\n",
    "        return extracted_data\n",
    "    \n",
    "    except KeyError as key_err:\n",
    "        print(f\"Key error: {key_err}. The API structure may have changed.\")\n",
    "        return None\n",
    "    except TypeError as type_err:\n",
    "        print(f\"Type error: {type_err}. There might be an issue with the data structure.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def save_to_parquet(data, filename='company_data.parquet'):\n",
    "    \"\"\"\n",
    "    Save the extracted data to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "    - data (dict): The extracted data.\n",
    "    - filename (str): The filename for the Parquet file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame([data])\n",
    "        df.to_parquet(filename, engine='pyarrow', index=False)\n",
    "        print(f\"Data has been saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving to Parquet: {e}\")\n",
    "\n",
    "        \n",
    "def main():\n",
    "    # Get the API key from a secrets file\n",
    "    try:\n",
    "        with open('secrets.txt', 'r') as file:\n",
    "            api_key = file.read().strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the secrets file: {e}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # Get the permalink as a user input\n",
    "    permalink = input(\"Enter the permalink of the company to search: \").strip()\n",
    "\n",
    "    # Construct the URL with the provided permalink\n",
    "    url = f\"https://api.crunchbase.com/v4/data/entities/organizations/{permalink}\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"X-cb-user-key\": api_key\n",
    "    }\n",
    "    params = {\n",
    "        \"card_ids\": [\"fields\"]\n",
    "    }\n",
    "\n",
    "    # Step 1: Fetch data from the API\n",
    "    data = fetch_data_from_api(url, headers, params)\n",
    "\n",
    "    # Step 2: Extract the required fields\n",
    "    if data:\n",
    "        extracted_data = extract_fields(data)\n",
    "        \n",
    "        # Step 3: Save the data to a Parquet file\n",
    "        if extracted_data:\n",
    "            save_to_parquet(extracted_data)\n",
    "        else:\n",
    "            print(\"Data extraction failed. The required fields may not be present in the response.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the API.\")\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e9d88d-a052-4ab7-9e5b-792aba3acde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------+----------------------+--------------------------------------------+-----------+------------+---------------+\n",
      "| permalink |        website_url        |      updated_at      |                  linkedin                  |   city    |   region   |    country    |\n",
      "+-----------+---------------------------+----------------------+--------------------------------------------+-----------+------------+---------------+\n",
      "|  konsus   | https://www.superside.com | 2024-02-01T05:45:15Z | https://www.linkedin.com/company/superside | Palo Alto | California | United States |\n",
      "+-----------+---------------------------+----------------------+--------------------------------------------+-----------+------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def print_dataframe(df):\n",
    "    \"\"\"\n",
    "    Print the DataFrame in a structured and readable format.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The DataFrame to be printed.\n",
    "    \"\"\"\n",
    "    print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "def main():\n",
    "    # Load the DataFrame from the Parquet file\n",
    "    try:\n",
    "        df = pd.read_parquet('company_data.parquet')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the Parquet file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Print the DataFrame using the structured format\n",
    "    print_dataframe(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a007d-15ee-40e5-ad70-1364ebfe845f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
